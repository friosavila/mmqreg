[TextBlock(text="<edited_text>\ntitle: Estimating Quantile Regressions with Multiple Fixed Effects through Method of Moments \\tnoteref{t1,t2}\nauthor:\n  - name: Fernando Rios-Avila\n    email: friosavi@levy.org\n    affiliations: \n        - id: levy\n          name: Levy Economics Institute of Bard College\n          city: Annandale-on-Hudson, NY\n          country: USA          \n    attributes:\n        corresponding: true\n  - name: Leonardo Siles\n    email: leonardo.siles@ucb.edu.bo\n    affiliations:\n        - id: ucb\n          name: Universidad Cat√≥lica Boliviana\n          city: La Paz\n          country: Bolivia\n  - name: Gustavo Canavire-Bacarreza\n    email: gcanavire@worldbank.org\n    affiliations:\n        - id: wb\n          name: The World Bank                 \n          city: Washington, D.C.\n          country: USA\nabstract: |\n  This paper proposes a new method to estimate quantile regressions with multiple fixed effects. The method, which expands on the strategy proposed by @mss2019, allows for the inclusion of multiple fixed effects and provides various alternatives for the estimation of standard errors. We provide Monte Carlo simulations to show the finite sample properties of the proposed method in the presence of two sets of fixed effects. Finally, we apply the proposed method to estimate the determinants of the surplus of government as a share of GDP, allowing for both time and country fixed effects.\n  \nkeywords: \n  - Fixed effects\n  - Linear heteroskedasticity\n  - Location-scale model\n  - Quantile regression\n\ndate: last-modified\nbibliography: bibliography.bib\nformat:\n  elsevier-pdf:\n    keep-tex: true\n    journal:\n      formatting: review\n      model: 1p\n      cite-style: authoryear\n      number-depth: 2\ninclude-in-header: \n      text: |\n        \\tnotetext[t1]{The opinions expressed in this paper are those of the authors and do not necessarily reflect the views of the World Bank, its Board of Directors, or the countries it represents.}    \n        \\tnotetext[t2]{The authors would like to thank Enrique Pinzon and Joao Santos-Silva for their helpful comments and suggestions.}   \n\n---\n\n<!--\nHow to Render this? Lik this:\nquarto render article.qmd --to elsevier-pdf \n\n --> \n\n # Introduction\n\n Quantile regression (QR), introduced by @koenkerbasset1978, is an estimation strategy used for modeling the relationships between explanatory variables X and the conditional quantiles of the dependent variable $Q_y (\\tau|x)$. Using QR one can obtain richer characterizations of the relationships between dependent and independent variables, by exploring how the variables relate along the entire conditional distribution. \n\n A relatively recent development in the literature has focused on extending quantile regressions analysis to include individual fixed effects in the framework of panel data. However, as described in @neymanscott1948 and @lancaster2000, when individual fixed effects are included in quantile regression analysis, an incidental parameter problem is generated. While many strategies have been proposed for estimating this type of model (see @galvao2017quantile for a brief review), neither has become standard because of their restrictive assumptions regarding the inclusion of individual and multiple fixed effects, the computational complexity, and implementation. \n\n More recently, @mss2019 (MSS hereafter) proposed a methodology based on a conditional location-scale model, similar to the one described in @he1997 and @zhao2000, for the estimation of quantile regressions models for panel data via a method of moments. This method allows individual fixed effects to have heterogeneous effects on the entire conditional distribution of the outcome, rather than constraining their effect to be a location shift only, as in @canay2011, @koenker2004, and @lamarche2010. \n\n In principle, under the assumption that the data-generating process behind the data is based on a multiplicative heteroskedastic process that is linear in parameters [@mss2019, @he1997, @zhao2000, @cameron2005], the effect of a variable $X$ on the $q_{th}$ quantile can be derived as the combination of a location effect and a scale effect moderated by the quantile of an underlying i.i.d. error. For statistical inference, MSS derives the asymptotic distribution of the estimator, suggesting the use of bootstrap standard errors, as well. \n\n This methodology is not meant to substitute for the use of standard quantile regression analysis. That said, given the assumptions required for the identification of the model, it provides a simple and fast alternative for the estimation of quantile regression models with individual fixed effects. \n\n In this framework, our paper expands on @mss2019 in two ways. First, making use of the properties of generalized method of moments (GMM) estimators, we derive various alternatives for the estimation of standard errors based on the empirical influence functions of the estimators. Even if the model is correctly specified, robust standard errors perform better than GLS standard errors due to small violations of the model assumptions due to sampling variability. Furthermore, clustered standard errors may help to further account for typically unobserved correlations across observations. Second, we reconsider the application of Frisch-Waugh-Lovell (FWL) theorem [@frishwaugh1933 and @lovell1963] to extend the MSS estimator and allow for the inclusion of multiple fixed effects. This extension may be useful for empirical analysis, as it is common to control for multiple fixed effects such as individual and time fixed effects.  \n\n The rest of the paper is structured as follows: section 2 presents the basic setup of the location-scale model described in @he1997 and @zhao2000, tying the relationship between the standard quantile regression model and the location-scale model. It also revisits the methodology of MSS, proposing alternative estimators for the standard errors based on the properties of GMM estimators and the empirical influence functions. It also shows that the FWL theorem can be used to control for multiple fixed effects. Section 3 presents the results of a small simulation study, and section 4 illustrates the application of the proposed methods with one empirical example. Section 5 concludes.\n\n # Methodology {#sec-method}\n\n ## Quantile Regression: Location-Scale model {#sec-betas}\n\n Quantile regressions are used to identify relationships between the explanatory variables $X$ and the conditional quantiles of the dependent variable $Q_y(\\tau|X)$. This relationship is commonly assumed to follow a linear functional form: \n\n $$Q_y(\\tau|X) =X\\beta(\\tau)\n$$ {#eq-eq1}\n\n This allows for a linear effect of $X$ on $Y$, but that could vary across values of $\\tau$.  \n\n An alternative formulation of quantile regressions is the location-scale model. This approach assumes that the conditional quantile of $Y$ given $X$ and $\\tau$ can be expressed as a combination of two models: the location model, which describes the central tendency of the conditional distribution; and the scale model, which describes deviations from the central tendency: \n\n $$Q_y(\\tau|X) =X\\beta+X\\gamma(\\tau)\n$$ {#eq-eq2}\n\n Here, the location parameters $\\beta$ are typically identified using a linear regression model (as in @mss2019) or a median regression (as in @he1997 and @zhao2000) and the scale parameters $\\gamma(\\tau)$ can be estimated using standard approaches. \n\n Both the standard quantile regression (@eq-eq1) and the location-scale specification (@eq-eq2) can be estimated as the solution to a weighted minimization problem: \n\n $$\\hat{\\beta}(\\tau) = \\underset{\\beta}{\\operatorname{argmin}}\n\\left( \\sum_{i\\in y_i\\geq x_i'\\beta} \\tau (y_i - x_i'\\beta) - \\sum_{i\\in y_i<x_i'\\beta} (1-\\tau)(y_i - x_i'\\beta) \\right)\n$$ {#eq-eq3}\n\n One characteristic of this estimator is that the $\\beta(\\tau)$ coefficients are identified locally and thus the estimated quantile coefficients will exhibit considerable variation when analyzed across $\\tau$. It is also implicit that if one requires an analysis of the entire distribution, it would be necessary to estimate the model for each quantile.[^1] \n\n [^1]: There are other estimators that provide smoother estimates for the quantile regression coefficients using a kernel local weighted approach [@kaplan2017], as well as identifying the full set of quantile coefficients while simultaneously assuming some parametric functional forms [@frumentobotai2016].\n\n One insightful extension to the location-scale parameterizations suggested by @he1997, @zhao2000, @cameron2005, and @mss2019 is to assume that the data-generating process (DGP) can be written as a linear model with a multiplicative heteroskedastic process that is linear in parameters.[^2] \n\n [^2]: @mss2019 also discuss a model where heteroskedasticity can be an arbitrary nonlinear function $\\sigma(x_i'\\gamma)$, but develop the estimator for the linear case, i.e., when $\\sigma()$ is the identity function.\n\n $$\\begin{aligned}\ny_i &=x_i'\\beta+\\nu_i \\\\\n\\nu_i &=\\varepsilon_i \\times x_i'\\gamma \n\\end{aligned}\n$$ {#eq-eq4}\n\n Under the assumption that $\\varepsilon$ is an i.i.d. unobserved random variable that is independent of $X$, the conditional quantile of $Y$ given $X$ and $\\tau$ can be written as \n\n $$Q_y(\\tau|X) =X\\beta+Q_\\varepsilon(\\tau) \\times X\\gamma \n$$ {#eq-eq5}\n\n In this setup, the traditional quantile coefficients are identified as the location model coefficients plus the scale model coefficients moderated by the $\\tau_{th}$ unconditional quantile of the standardized error $\\varepsilon$. For simplicity, we will use $q_\\tau$ to denote $Q_\\varepsilon(\\tau)$ in the rest of the paper. \n\n $$\\beta(\\tau) = \\beta + q_\\tau \\times \\gamma \n$$ {#eq-eq6}\n\n While this specification imposes a strong assumption on the DGP, it has two advantages over the standard quantile regression model. First, because the location-scale model can be identified globally, with only a single parameter ($q_\\tau$) requiring local estimation, this estimation approach will be more efficient than the standard quantile regression model [@zhao2000]. Second, under the assumption that $X\\gamma$ is strictly positive, the model will produce quantile coefficients that do not cross [@he1997].  \n\n Following MSS, the quantile regression model defined by @eq-eq5 can be estimated using a generalized method of moments approach. And while it is possible to identify all coefficients ($\\beta,\\gamma, q_\\tau$) simultaneously, we describe and use the implementation approach advocated by MSS, which identifies each set of coefficients separately. \n\n First, the location model can be estimated using a standard linear regression model, where the dependent variable is the outcome $Y$ and the independent variables are the explanatory variables $X$ (including a constant) with an error $u$, which is by definition heteroskedastic. In this case, the location-model coefficients are identified under the following condition: \n\n $$\\begin{aligned}\n      y_i &=x_i'\\beta+\\nu_i \\\\\n      E\\big[ x_i \\nu_i\\big] &=0\n      \\end{aligned}\n$$ {#eq-eq7}\n\n Second, after the location model is estimated, the scale coefficients can be identified by modeling heteroskedasticity as a linear function of characteristics $X$. For this, we use the absolute value of the errors from the location model $u$ as the dependent variable, which allows us to estimate the conditional standard deviation (rather than conditional variance) of the errors. In this case, the coefficients are identified under the following condition: \n\n $$\\begin{aligned}\n  |\\nu_i| &=x_i'\\gamma+\\omega_i \\\\\n   E\\big[ x_i (|\\nu_i| -x_i'\\gamma ) \\big] &=0\n  \\end{aligned}\n$$ {#eq-eq8}\n\n It should be noticed that the estimation of the standard errors (next section) requires that the Scale component prediction $x_i'\\gamma$ is strictly positive, because it represents the conditional standard deviation of the error $\\nu_i$. Because this component is identified using a linear model, some values for $x_i'\\gamma$ may be negative, which will affect the estimation of the standard errors, as shown in the simulation study. \n\n Third, given the location and scale coefficients, the $\\tau_{th}$ quantile of the error $\\varepsilon$ can be estimated using the following condition: \n\n $$\\begin{aligned}\n  E\\left[  \\mathbb{1}\\left(x_i' (\\beta +   \\gamma q_\\tau) \\geq y_i \\right) - \\tau \\right] &=0  \\\\\n  E\\left[  \\mathbb{1}\\left(   q_\\tau \\geq \\frac{y_i-x_i'\\beta}{x_i'\\gamma} \\right) - \\tau \\right] &=0  \\\\\n  \\end{aligned}\n$$ {#eq-eq9}\n\n where one identifies the quantile of the error $\\varepsilon$ using standardized errors $\\frac{y_i-x_i'\\beta}{x_i'\\gamma}$ or by finding the values that identify the overall quantile coefficients $\\beta(\\tau)=\\beta + \\gamma q_\\tau$. Afterwards, the conditional quantile coefficients are simply defined as the combination of the location and scale coefficients. \n\n\n\n ## Standard Errors: GLS, Robust, Clustered {#sec-se}\n\n As discussed in the previous section, the estimation of quantile regression coefficients using the location-scale model with heteroskedastic linear errors can be estimated using a the following set of moments, which fits within the GMM framework: \n\n $$\\begin{aligned}\n  E[x_i \\nu_i  ] &= E[h_{1,i}]=0 \\\\\n  E[x_i  (|\\nu_i|-x_i \\gamma) ] &=E[h_{2,i}]=0 \\\\\n  E\\left[  \\mathbb{1}\\left(   q_\\tau\\geq \\frac{y_i-x_i'\\beta}{x_i'\\gamma} \\right) - \\tau \\right]  &=E[h_{3,i}]=0 \n  \\end{aligned}\n$${#eq-eq10}\n\n Under the conditions described in @newey_chapter_1994 (see section 7), @cameron2005 (see chapter 6.3.9), or as shown in @mss2019, the location, scale, and residual quantile coefficients are asymptotically normal.[^3] \n\n [^3]: @zhao2000 also shows that the quantile coefficients for the location-scale model follow a normal distribution, but uses the assumption that the location model is derived using a least absolute deviation approach (median regression).\n\n Call $\\theta=[ \\beta' \\ \\ \\gamma' \\ \\ q_\\tau ]'$ the set of coefficients that are identified by the moment conditions in @eq-eq10, a just identified model, and the function $h_i$ is a vector function that stacks all the moments described in @eq-eq10 at the individual level. Then $\\hat\\theta$ follows a normal distribution with mean $\\theta$ and variance-covariance matrix $V(\\theta)$ that is estimated as \n\n $$\n\\hat{V}(\\hat\\theta)=\\frac{1}{N} \n\\bar G(\\hat\\theta)^{-1} \n\\left( \\frac{1}{N} \\sum_{i=1}^N h_i h_i'  \\Big|_{\\theta=\\hat\\theta} \\right) \n\\bar G(\\hat\\theta)^{-1} \n$$\n\n which is equivalent to the Eicker-White heteroskedasticity-consistent estimator for least-squares estimators. \n\n Here, the inner product is the moment covariance matrix and $\\bar{G}(\\theta)$", type='text')]

\nIn the case of unbalanced setups with multiple groups, the estimation involves iterative processes for which various approaches have been suggested and implemented (see, for example, @correia_feasible_nodate, @gaure2013, @rios2015, among others).\n\nWhen applying the partialing-out approach, some modifications to the approach described in @sec-betas are needed.\n\nFirst, for all dependent and independent variables in the model ($w=y,x$), we partial out the group fixed effects and obtain the centered-residualized variables:\n\n$$\\begin{aligned}\nw_{i} &= \\delta_{g1}^w + \\delta_{g2}^w + u_{i}^w \\\\\nw_{i}^{rc} &= E(w_{i}) + \\hat{u}_{i}^w\n\\end{aligned}$$\n\nAfterward, we estimate the location model using the centered-residualized variables:[^8]\n\n[^8]: Using centered-residualized variables allows us to include a constant in the model specification, which simplifies the derivation of the influence functions. However, as with other fixed effects models, the constant is not identified and thus should not be interpreted.\n\n$$y_{i}^{rc} = x_{i}^{rc'} \\beta + \\nu_{i}$$\n\nBecause $|\\hat \\nu_i|$ is the dependent variable for the scale model, we apply the partialing out and recentering to this expression ($|\\hat \\nu_i|^{rc}$), and use that to estimate the following model:\n\n$$|\\hat\\nu_{i}|^{rc} = x_{i}^{rc'} \\gamma + \\omega_{i}$$\n\nFinally, the standardized residuals $\\varepsilon_i$ can be obtained as follows:\n\n$$\\hat{\\varepsilon}_{i} = \\frac{\\nu_{i}}{|\\hat\\nu_{i}|- \\hat \\omega_{i}}$$\n\nwhere $|\\hat\\nu_{i}|- \\hat \\omega_{i}$ is the prediction for the conditional standard deviation $\\sigma(x_i)=x_{i}' \\gamma + \\zeta_{g1} + \\zeta_{g2}$\n\nThe $\\tau_{th}$ quantile of the error $\\varepsilon$ can be estimated as usual, and the variance-covariance matrices obtained in the same way as before (see @sec-se) by using $x_{i}^{rc}$ instead of $x_{i}$ when estimating the influence functions for all estimated coefficients.\n\n# Simulation Evidence\n\nTo show the performance of the extended strategy, we implement a small simulation study. We consider a simple model with a single explanatory variable $x$. In contrast with MSS, we consider a two-way fixed effect structure. For this exercise, we consider the following data-generating process:\n\n$$y_i = \\alpha_{1i} + \\alpha_{2i} + x_i + (2+x_i + \\alpha_{1i} + \\alpha_{2i} ) \\varepsilon_i$$\n\nwhere $\\alpha_{1i}\\sim \\chi^2(1)$, $\\alpha_{2i} \\sim \\chi^2(1)$, and $x_i = 0.5 * (\\chi_i +0.5(\\alpha_{1i}+\\alpha_{2i}))$, with $\\chi_i \\sim \\chi^2(1)$. We only consider the case when the error term $\\varepsilon_i$ is assumed to follow a centered $\\chi^2$ distribution.[^99]\n\n[^99]: Specifically, we assume $\\varepsilon=\\frac{r_i}{5}-1$, where $r_i$ follows a chi-squared distribution such that $r_i \\sim \\chi^2(5)$. Simulations under the assumption of normal errors are available upon request.\n\nWe assume that there are 50 mutually exclusive groups for each set of fixed effects. Observations are assigned to each subgroup randomly using a uniform distribution between 1 and 50.\n\nTo assess the alternative standard error estimators, we consider a second data-generating process where the error term is correlated within clusters. For this, we assume observations are assigned randomly to 100 mutually exclusive groups, which are independent from the fixed effect groups. In this setup, the data-generating process is:\n\n$$\\begin{aligned}\ny_i &= \\alpha_{1i} + \\alpha_{2i} + x_i + (2+x_i + \\alpha_{1i} + \\alpha_{2i} )*\\kappa_i \\\\\n\\kappa_i &= inv-\\chi^2_5(r_{i})/5-1 \\\\\nr_i &= \\Phi((\\sqrt{.25}*s_{i}+\\sqrt{.75}*s_{g}))\n\\end{aligned}$$\n\nwhere $s_{i}\\sim N(0,1)$ and $s_{g}\\sim N(0,1)$, are errors that vary across individuals $i$ or across clusters $g$. $\\Phi()$ is the cumulative distribution function of a normal distribution, and $inv-\\chi^2_5()$ is the inverse function for a Chi-2 distribution with 5 degrees of freedom. With this setup, we generate an error structure with a strong intra-cluster correlation, but without affecting the model specification assumption.[^9]\n\n[^9]: For the implementation, we first estimate the model using the full sample, then randomly assign each observation into one of two groups, and finally reestimate the quantile coefficients for each group. The bias-corrected estimator is then obtained as $\\hat\\beta(\\tau)_{jkc}=2*\\hat\\beta(\\tau)_{full}-0.5*\\big(\\hat\\beta(\\tau)_{s1}+\\hat\\beta(\\tau)_{s2}\\big)$.\n\n[^88: This is also consistent with simulations with a single fixed effect]\n\nWe consider sample sizes of 500, 1000, 2000, and 4000 observations, which implies an average of 10, 20, 40, and 80 observations per group. The model is estimated using the location-scale model with heteroskedastic linear errors, and we report the coefficients for the 25th and 75th quantiles. We run this exercise 5000 times. @tbl-sim1 reports the bias, simulated standard error, and mean squared error, using the first data generation structure only. We also report the results obtained using an adaptation bias-corrected estimator based on the split-panel jackknife estimator proposed by @dhaene2015.\n\nSimilar to the findings in MSS, we find that while the estimator presents a substantial bias when the sample is small ($N=500$), this bias shrinks as the sample size increases. As MSS describes, the bias seems to be proportional to the sample size, or more precisely to the average number of observations per sub-group. Interestingly, the bias-corrected estimator presents an almost 0 bias for the 25th percentile, even when the samples are small. In contrast, when considering the 75th percentile, the simple estimator shows smaller bias than the Jacknife estimator. In either case, despite the bias reduction obtained using the JKC estimator, the standard errors are larger than without correction. For the 25th quantile, the reduction in bias is large enough to produce a smaller Mean Squared Error (MSE) than the simple estimator. This is similar to the results of MSS.\n\nTo evaluate the performance of the different standard errors, we present bias, 95% coverage of the bias-corrected estimates, as well as the simulated standard errors, average and median of the standard errors obtained using the GLS, robust SE, and clustered standard SE. @tbl-sim2 considers the d.g.p. without intra-cluster correlation, while @tbl-sim3 considers the d.g.p. that induces intra-cluster correlations. All simulations consider 5000 repetitions.\n\nThe bias magnitude in @tbl-sim2 and @tbl-sim3 is comparable to those observed in @tbl-sim1, with simulated standard errors that show to be slightly larger when we allow for intra-cluster correlations, just as expected. When assuming there is no need to cluster standard errors (@tbl-sim2), the coverage associated with GLS standard errors is above 95% when the samples are small, but it approximates to 95% as the sample size increases. On the other hand, the coverage rates associated with Robust Standard errors are closer to 90%, albeit increasing slightly for larger samples.\n\nOne of the main reasons that the GLS-Standard errors achieve higher than expected rates of coverage may be related to the fact that the standard error estimator is very sensitive to near-zero predictions from the scale model. As shown in @tbl-sim2, average and median GLS-SE are considerably larger than the simulated standard errors when the samples are small. While robust standard errors are less sensitive to this problem, producing more stable results, they tend to underestimate the magnitude of the true standard errors in small samples. This translates into the lower coverage rates.\n\nWhen we consider the presence of Intra-Cluster correlation, @tbl-sim3, we still observe similar problems with the GLS-SE, albeit with high coverage rates. While Robust and Clustered Standard errors are on average smaller than the Simulated Standard errors, coverage rates are above 90%. Clustered standard errors perform the best only when the sample size is large, with Robust standard errors producing low Standard error estimates.\n\nOverall, the simulation study shows that using the GLS-SE estimator may be appropriate when the sample is relatively large. When there is suspected presence of intra-cluster correlation, the use of clustered standard errors is recommended in larger samples. However, when the sample is small, the use of robust standard errors may be appropriate if GLS standard errors when there is the risk of near-zero predictions from the scale model.\n

\nFurthermore, we have assessed the impact of intracluster correlation on the performance of standard error estimations. Our findings emphasize the importance of using appropriate standard error estimators to ensure accurate inference. In particular, we find that GLS standard errors are biased when the scale model predictions are close to zero or negative, and that Robust and clustered standard errors are more stable in those scenarios. Clustered standard errors perform the best in the presence of intra-cluster correlation, but the advantage is only evident when the sample size is large.\n\nFinally, we have illustrated the application of our extended methodology using data from @persson_economic_2005. Our results are consistent with those reported in @mss2019, and we are able to provide robust and clustered standard errors for the location and scale coefficients. We find that the GLS standard errors are almost twice as large as the robust and clustered standard errors, which is consistent with the results from our simulation study. Nevertheless, there is no drastic change in the original conclusions.\n

